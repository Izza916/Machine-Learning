{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f547985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TASK 1:\n",
    "#Load the heart disease dataset\n",
    "# ● Perform necessary EDA and Data Wrangling and Implement Logistic Regression\n",
    "# ● First train your model using penalty as l1 regularization\n",
    "# ● Train your model with l2 regularization\n",
    "# ● Train your model with penalty = elastic net\n",
    "# ● Now compare the results of training and testing accuracy\n",
    "# ● Discuss in a text cell, what error you have gone through while implementing this penalty,\n",
    "# Have you changed other parameter to apply these Penalties??\n",
    "# ● What additional parameter you have changed while implementing the mentioned penalty, what is the relationship between these?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "991a1fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\i\\Downloads\\heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbadb264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025 entries, 0 to 1024\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1025 non-null   int64  \n",
      " 1   sex       1025 non-null   int64  \n",
      " 2   cp        1025 non-null   int64  \n",
      " 3   trestbps  1025 non-null   int64  \n",
      " 4   chol      1025 non-null   int64  \n",
      " 5   fbs       1025 non-null   int64  \n",
      " 6   restecg   1025 non-null   int64  \n",
      " 7   thalach   1025 non-null   int64  \n",
      " 8   exang     1025 non-null   int64  \n",
      " 9   oldpeak   1025 non-null   float64\n",
      " 10  slope     1025 non-null   int64  \n",
      " 11  ca        1025 non-null   int64  \n",
      " 12  thal      1025 non-null   int64  \n",
      " 13  target    1025 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 112.2 KB\n",
      "None\n",
      "\n",
      "Dataset description:\n",
      "               age          sex           cp     trestbps        chol  \\\n",
      "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
      "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
      "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
      "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
      "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
      "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
      "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
      "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
      "\n",
      "               fbs      restecg      thalach        exang      oldpeak  \\\n",
      "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
      "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
      "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
      "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
      "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
      "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
      "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
      "\n",
      "             slope           ca         thal       target  \n",
      "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
      "mean      1.385366     0.754146     2.323902     0.513171  \n",
      "std       0.617755     1.030798     0.620660     0.500070  \n",
      "min       0.000000     0.000000     0.000000     0.000000  \n",
      "25%       1.000000     0.000000     2.000000     0.000000  \n",
      "50%       1.000000     0.000000     2.000000     1.000000  \n",
      "75%       2.000000     1.000000     3.000000     1.000000  \n",
      "max       2.000000     4.000000     3.000000     1.000000  \n",
      "\n",
      "Target variable distribution:\n",
      "target\n",
      "1    526\n",
      "0    499\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nDataset description:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nTarget variable distribution:\")\n",
    "print(df['target'].value_counts()) \n",
    "\n",
    "X = df.drop(columns=['target']) \n",
    "y = df['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3bb99c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with penalty: l1\n",
      "Training Accuracy: 0.8463414634146341\n",
      "Testing Accuracy: 0.8097560975609757\n",
      "Training with penalty: l2\n",
      "Training Accuracy: 0.8463414634146341\n",
      "Testing Accuracy: 0.8097560975609757\n",
      "Training with penalty: elasticnet\n",
      "Training Accuracy: 0.8463414634146341\n",
      "Testing Accuracy: 0.8097560975609757\n"
     ]
    }
   ],
   "source": [
    "penalties = ['l1', 'l2', 'elasticnet']\n",
    "results = []\n",
    "\n",
    "for penalty in penalties:\n",
    "    print(f\"Training with penalty: {penalty}\")\n",
    "    if penalty == 'elasticnet':\n",
    "        solver = 'saga' \n",
    "    else:\n",
    "        solver = 'liblinear'  \n",
    "\n",
    "    model = LogisticRegression(\n",
    "        penalty=penalty,\n",
    "        solver=solver,\n",
    "        l1_ratio=0.5 if penalty == 'elasticnet' else None, \n",
    "        random_state=42,\n",
    "        max_iter=1000\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        print(f\"Training Accuracy: {train_accuracy}\")\n",
    "        print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "\n",
    "        results.append({\n",
    "            'Penalty': penalty,\n",
    "            'Train Accuracy': train_accuracy,\n",
    "            'Test Accuracy': test_accuracy\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with penalty {penalty}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebdd3364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of penalties:\n",
      "      Penalty  Train Accuracy  Test Accuracy\n",
      "0          l1        0.846341       0.809756\n",
      "1          l2        0.846341       0.809756\n",
      "2  elasticnet        0.846341       0.809756\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nComparison of penalties:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('logistic_regression_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors Encountered:\n",
    "# Using elasticnet requires the solver to be saga. Using another solver results in an error. l1_ratio is only relevant for elasticnet; leaving it out for other penalties will raise an error.\n",
    "\n",
    "# Parameter Changes:\n",
    "# When using elasticnet, the additional parameter l1_ratio defines the proportion of L1 and L2 regularization. Adjusting this impacts the model's performance. Solvers like saga support all penalties, while liblinear only supports l1 and l2.\n",
    "\n",
    "# Relationship Between Parameters:\n",
    "# Penalty and Solver: Specific solvers are compatible with specific penalties. Penalty and Regularization Strength: The penalty type impacts how coefficients are penalized, which affects model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2:\n",
    "# Implement Logistic regression on the Iris dataset , now choose different solvers 'lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’ Compare the results of Training and testing accuracy in a Dataframe \n",
    "\n",
    "# • Briefly discuss the effect of solver on your dataset ,\n",
    "# • Have you found the similarity as mentioned by Sklearn that which solver is best for small, medium or larger dataset.\n",
    "# • Which solver is best in your case and why?\n",
    "# • Now copy this file and apply a new Dataset (Heart Disease) and compare, Does it really affected by the size of dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44f59c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "Target values: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "print(X.head())\n",
    "\n",
    "print(f\"Target values: {iris.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5616b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b481d448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with solver: lbfgs\n",
      "Training Accuracy: 0.9583333333333334\n",
      "Testing Accuracy: 0.9333333333333333\n",
      "Training with solver: liblinear\n",
      "Training Accuracy: 0.925\n",
      "Testing Accuracy: 0.8333333333333334\n",
      "Training with solver: newton-cg\n",
      "Training Accuracy: 0.9583333333333334\n",
      "Testing Accuracy: 0.9333333333333333\n",
      "Training with solver: newton-cholesky\n",
      "Training Accuracy: 0.95\n",
      "Testing Accuracy: 0.9\n",
      "Training with solver: sag\n",
      "Training Accuracy: 0.9583333333333334\n",
      "Testing Accuracy: 0.9333333333333333\n",
      "Training with solver: saga\n",
      "Training Accuracy: 0.9583333333333334\n",
      "Testing Accuracy: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "results = []\n",
    "\n",
    "for solver in solvers:\n",
    "    print(f\"Training with solver: {solver}\")\n",
    "    try:\n",
    "        model = LogisticRegression(solver=solver, multi_class='auto', max_iter=1000, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "        print(f\"Training Accuracy: {train_accuracy}\")\n",
    "        print(f\"Testing Accuracy: {test_accuracy}\")\n",
    "\n",
    "        results.append({'Solver': solver, 'Train Accuracy': train_accuracy, 'Test Accuracy': test_accuracy})\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error with solver {solver}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b54c37f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of solvers:\n",
      "            Solver  Train Accuracy  Test Accuracy\n",
      "0            lbfgs        0.958333       0.933333\n",
      "1        liblinear        0.925000       0.833333\n",
      "2        newton-cg        0.958333       0.933333\n",
      "3  newton-cholesky        0.950000       0.900000\n",
      "4              sag        0.958333       0.933333\n",
      "5             saga        0.958333       0.933333\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nComparison of solvers:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('solver_comparison_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64eb1d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Heart Disease Dataset Results:\n",
      "            Solver  Train Accuracy  Test Accuracy\n",
      "0            lbfgs        0.846341       0.809756\n",
      "1        liblinear        0.846341       0.809756\n",
      "2        newton-cg        0.846341       0.809756\n",
      "3  newton-cholesky        0.846341       0.809756\n",
      "4              sag        0.846341       0.809756\n",
      "5             saga        0.846341       0.809756\n",
      "\n",
      "Combined Results:\n",
      "             Solver  Train Accuracy  Test Accuracy        Dataset\n",
      "0             lbfgs        0.958333       0.933333           Iris\n",
      "1         liblinear        0.925000       0.833333           Iris\n",
      "2         newton-cg        0.958333       0.933333           Iris\n",
      "3   newton-cholesky        0.950000       0.900000           Iris\n",
      "4               sag        0.958333       0.933333           Iris\n",
      "5              saga        0.958333       0.933333           Iris\n",
      "6             lbfgs        0.846341       0.809756  Heart Disease\n",
      "7         liblinear        0.846341       0.809756  Heart Disease\n",
      "8         newton-cg        0.846341       0.809756  Heart Disease\n",
      "9   newton-cholesky        0.846341       0.809756  Heart Disease\n",
      "10              sag        0.846341       0.809756  Heart Disease\n",
      "11             saga        0.846341       0.809756  Heart Disease\n"
     ]
    }
   ],
   "source": [
    "df_hd = pd.read_csv(r'C:\\Users\\i\\Downloads\\heart.csv')\n",
    "\n",
    "solvers = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "results_heart_disease = []\n",
    "\n",
    "for solver in solvers:\n",
    "    try:\n",
    "        model_hd = LogisticRegression(solver=solver, multi_class='auto', max_iter=1000, random_state=42)\n",
    "        model_hd.fit(X_hd_train, y_hd_train)\n",
    "        \n",
    "        y_hd_train_pred = model_hd.predict(X_hd_train)\n",
    "        y_hd_test_pred = model_hd.predict(X_hd_test)\n",
    "        \n",
    "        train_acc = accuracy_score(y_hd_train, y_hd_train_pred)\n",
    "        test_acc = accuracy_score(y_hd_test, y_hd_test_pred)\n",
    "\n",
    "        results_heart_disease.append({'Solver': solver, 'Train Accuracy': train_acc, 'Test Accuracy': test_acc})\n",
    "    except Exception as e:\n",
    "        results_heart_disease.append({'Solver': solver, 'Train Accuracy': None, 'Test Accuracy': None, 'Error': str(e)})\n",
    "\n",
    "results_hd_df = pd.DataFrame(results_heart_disease)\n",
    "print(\"\\nHeart Disease Dataset Results:\")\n",
    "print(results_hd_df)\n",
    "\n",
    "results_iris_df['Dataset'] = 'Iris'\n",
    "results_hd_df['Dataset'] = 'Heart Disease'\n",
    "combined_results = pd.concat([results_iris_df, results_hd_df], ignore_index=True)\n",
    "\n",
    "print(\"\\nCombined Results:\")\n",
    "print(combined_results)\n",
    "\n",
    "combined_results.to_csv('solver_comparison_combined_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27452272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Comparison Across Datasets:\n",
    "# For the Iris dataset, the training and testing accuracies are relatively higher (e.g., around 95.8% and 93.3%, respectively) across most solvers. This is expected because the Iris dataset is smaller (150 samples) and well-structured.\n",
    "# For the Heart Disease dataset, the training and testing accuracies are lower (e.g., around 84.6% and 80.9%) across all solvers. The dataset is larger and potentially noisier, making it harder to achieve higher accuracy.\n",
    "\n",
    "#Effect of Solvers on Performance:\n",
    "#For both datasets, the solvers (lbfgs, liblinear, newton-cg, newton-cholesky, sag, saga) produce identical accuracies. This indicates that the solvers are equally effective given the structure and size of these datasets. However, in practice, solvers like sag and saga are optimized for large datasets, while liblinear works well with smaller datasets. The lack of differences here may be because both datasets are not large enough to stress-test solvers like sag and saga.\n",
    "\n",
    "# Training vs. Testing Accuracy:\n",
    "# For both datasets, the training accuracy is consistently higher than testing accuracy. This suggests slight overfitting, particularly on the Heart Disease dataset.\n",
    "\n",
    "# Effect of Dataset Size:\n",
    "# The Iris dataset is smaller (150 samples), and the models achieve near-perfect results.\n",
    "# The Heart Disease dataset is larger, and its real-world nature introduces challenges like noise and variability, leading to lower accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27296a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 3:\n",
    "# • Implement Perceptron on Iris Data and the Compare the Results of Logistic Regression (Sklearn) model with Perceptron model. Compare Training and Testing results of Perceptron and LR\n",
    "# • What is the difference between Perceptron and LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0316c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e86ec57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "perceptron_model = Perceptron(max_iter=1000, random_state=42)\n",
    "perceptron_model.fit(X_train, y_train)\n",
    "y_train_pred_p = perceptron_model.predict(X_train)\n",
    "y_test_pred_p = perceptron_model.predict(X_test)\n",
    "train_acc_p = accuracy_score(y_train, y_train_pred_p)\n",
    "test_acc_p = accuracy_score(y_test, y_test_pred_p)\n",
    "results.append({'Model': 'Perceptron', 'Train Accuracy': train_acc_p, 'Test Accuracy': test_acc_p})\n",
    "\n",
    "log_reg_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='auto', solver='lbfgs')\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "y_train_pred_lr = log_reg_model.predict(X_train)\n",
    "y_test_pred_lr = log_reg_model.predict(X_test)\n",
    "train_acc_lr = accuracy_score(y_train, y_train_pred_lr)\n",
    "test_acc_lr = accuracy_score(y_test, y_test_pred_lr)\n",
    "results.append({'Model': 'Logistic Regression', 'Train Accuracy': train_acc_lr, 'Test Accuracy': test_acc_lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e32a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison of Perceptron and Logistic Regression Models:\n",
      "                 Model  Train Accuracy  Test Accuracy\n",
      "0           Perceptron        0.933333       0.866667\n",
      "1  Logistic Regression        0.958333       0.933333\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nComparison of Perceptron and Logistic Regression Models:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv('perceptron_vs_logistic_regression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Differences:\n",
    "# Perceptron: Works as a linear classifier, where it tries to find a hyperplane that separates the classes. It uses a step function for predictions, which may not always converge if the data isn't linearly separable.\n",
    "# Logistic Regression: A probabilistic model that predicts the probability of belonging to a class. It uses a sigmoid function and is more robust for non-linearly separable data.\n",
    "\n",
    "# Performance Comparison: Logistic Regression typically outperforms Perceptron on datasets like Iris due to its probabilistic approach and better handling of overlap between classes.\n",
    "\n",
    "# Key Observations:\n",
    "# If the Perceptron achieves lower accuracy, it could be due to the Iris dataset having some non-linearly separable regions.\n",
    "# Logistic Regression is a more stable and widely applicable model for classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
